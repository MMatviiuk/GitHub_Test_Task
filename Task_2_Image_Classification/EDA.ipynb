{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import argparse\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load and verify image\n",
    "\n",
    "def load_image(file_path):\n",
    "    \"\"\"\n",
    "    Load and verify an image. Return None if the image is invalid.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        Image object or None if the image is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        img.verify()  # Verify image integrity\n",
    "        img = Image.open(file_path)  # Reopen to display\n",
    "        img = img.convert(\"RGB\")  # Ensure RGB mode\n",
    "        return img\n",
    "    except (UnidentifiedImageError, OSError, AttributeError) as e:\n",
    "        print(f\"[WARNING] Skipped corrupted file: {file_path} ({e})\")\n",
    "        return None\n",
    "\n",
    "# Function for EDA visualization\n",
    "\n",
    "def visualize_dataset(data_dir, english_classes):\n",
    "    \"\"\"\n",
    "    Visualize the dataset by displaying class distribution and sample images.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory.\n",
    "        english_classes (list): English class names corresponding to dataset folders.\n",
    "    \"\"\"\n",
    "    class_dirs = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    counts = {}\n",
    "    for cls in class_dirs:\n",
    "        cls_path = os.path.join(data_dir, cls)\n",
    "        valid_files = [f for f in os.listdir(cls_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "        counts[cls] = len(valid_files)\n",
    "\n",
    "    df_counts = pd.DataFrame({\"Italian_Class\": class_dirs, \"Count\": list(counts.values()), \"English_Class\": english_classes})\n",
    "    print(\"Class distribution (Italian -> English):\")\n",
    "    print(df_counts)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_counts, x=\"English_Class\", y=\"Count\")\n",
    "    plt.title(\"Image Count per Animal Class (Animals-10 Dataset)\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nDisplaying one sample image per class:\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for idx, (italian_class, english_class) in enumerate(zip(class_dirs, english_classes), 1):\n",
    "        class_path = os.path.join(data_dir, italian_class)\n",
    "        files = [f for f in os.listdir(class_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "        for file in files:\n",
    "            img = load_image(os.path.join(class_path, file))\n",
    "            if img is not None:\n",
    "                plt.subplot(2, 5, idx)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"{english_class}\")\n",
    "                break\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main EDA execution\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to perform EDA on the dataset.\n",
    "    \"\"\"\n",
    "    data_dir = \"/kaggle/input/animals10/raw-img/\"\n",
    "    english_classes = ['horse', 'sheep', 'elephant', 'cat', 'squirrel', 'chicken', 'spider', 'cow', 'dog', 'butterfly']\n",
    "\n",
    "    if os.path.exists(data_dir):\n",
    "        print(f\"Dataset verified at: {data_dir}\")\n",
    "        visualize_dataset(data_dir, english_classes)\n",
    "    else:\n",
    "        print(f\"Dataset not found at {data_dir}. Check path or add dataset via Kaggle 'Add Data'.\")\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 59760,
     "sourceId": 840806,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
